rasa:
  enabled: true
  # Configure the service account which allows Rasa to interact with GCP resources like reading data from Cloud Storage buckets.
  serviceAccountName: assistant
  serviceAccount:
    create: true
    name: assistant
    annotations:
      iam.gke.io/gcp-service-account: ${SERVICE_ACCOUNT_ASSISTANT}
  settings:
    enableApi: true
    credentials:
      enabled: true
      additionalChannelCredentials:
        socketio:
          bot_message_evt: bot_uttered
          metadata_key: customData
          session_persistence: false
          user_message_evt: user_uttered
        rest: { }
    endpoints:
      models:
        enabled: false
      # Configure the assistant to use our PostgreSQL instance as the Tracker Store, which records the assistant's conversations.
      trackerStore:
        enabled: true
        type: sql
        dialect: postgresql
        url: ${DB_HOST}
        db: ${DB_ASSISTANT_DATABASE}
        username: ${DB_ASSISTANT_USERNAME}
        password: ${DB_ASSISTANT_PASSWORD}
        port: 5432
      # Configure the assistant to use Redis as the Rasa Lock Store.
      # This is needed when you have a high-load scenario that requires the Rasa server to be replicated across multiple instances. It ensures that even with multiple servers, the messages for each conversation are handled in the correct sequence without any loss or overlap.
      lockStore:
        enabled: true
        type: concurrent_redis
        password: ${REDIS_PASSWORD}
        port: 6379
        url: ${REDIS_HOST}
        use_ssl: false
        key_prefix: ${NAME}
      # Configure the assistant to use the Kafka broker. This allows us to perform further processing on the messages, like using the Rasa Studio Conversation View or Rasa Pro Analytics.
      eventBroker:
        enabled: true
        type: kafka
        security_protocol: SASL_PLAINTEXT
        sasl_mechanism: PLAIN
        topic: rasa
        url: kafka-controller-0.kafka-headless.${NAMESPACE}.svc.cluster.local:9092,kafka-controller-1.kafka-headless.${NAMESPACE}.svc.cluster.local:9092,kafka-controller-2.kafka-headless.${NAMESPACE}.svc.cluster.local:9092
        sasl_username: ${KAFKA_USER}
        sasl_password: 
          secretKeyRef:
            name: rasa-secrets
            key: kafkaSslPassword
        ssl_check_hostname: false
  # We'll configure Rasa to use Google Cloud Storage for remote storage, so we can load models from the buckets we created earlier.
  additionalArgs:
    - --remote-storage
    - gcs
  # Define the environment variables that Rasa needs to function and interact with the above services.
  # Note here that some of the values are plaintext environment variables and some are configured to be pulled from the Kubernetes Secret we created earlier.
  additionalEnv:
    - name: RASA_ENVIRONMENT
      value: production
    - name: BUCKET_NAME
      value: ${MODEL_BUCKET}
    - name: DB_HOST
      value: ${DB_HOST}
    - name: DB_DATABASE
      value: ${DB_ASSISTANT_DATABASE}
    - name: DB_USER
      value: assistant
    - name: DB_PASSWORD
      valueFrom:
        secretKeyRef:
          name: rasa-secrets
          key: dbPassword
    - name: KAFKA_PASSWORD
      valueFrom:
        secretKeyRef:
          name: rasa-secrets
          key: kafkaSslPassword
    - name: KAFKA_USER
      value: kafka
    - name: REDIS_PASSWORD
      valueFrom:
        secretKeyRef:
          name: rasa-secrets
          key: redisPassword
    - name: RASA_PRO_LICENSE
      valueFrom:
        secretKeyRef:
          name: rasa-secrets
          key: rasaProLicense
# Disable other Rasa components for now.
# https://rasa.com/docs/reference/integrations/analytics/
rasaProServices:
  enabled: false
# https://rasa.com/docs/action-server
actionServer:
  enabled: false
# https://rasa.com/docs/reference/integrations/tracing
tracing:
    enabled: false